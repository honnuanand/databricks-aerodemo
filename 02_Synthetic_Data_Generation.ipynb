{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf0e35d-2e0c-4f59-9981-95eee3569164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook 2: Synthetic Data Generation\n",
    "This notebook simulates realistic aircraft sensor data and writes it to a managed volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f9e5f1-4f40-40c7-b86e-ad1c7ffacc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🧪 Synthetic Data Generation\n",
    "\n",
    "This notebook generates synthetic datasets for the Aircraft AOG (Aircraft on Ground) demo. It simulates both sensor telemetry and maintenance event logs for a fleet of aircraft, and saves them as CSV files with timestamped filenames.\n",
    "\n",
    "## ✈️ Datasets Generated\n",
    "\n",
    "1. **`raw_sensor_data_*.csv`**\n",
    "   - Simulates daily sensor readings such as engine temperature, fuel efficiency, and vibration.\n",
    "   - Covers multiple aircraft models (e.g., A320, B737, A330).\n",
    "   - Includes a full calendar year of data.\n",
    "\n",
    "2. **`maintenance_events_*.csv`**\n",
    "   - Simulates scheduled and unscheduled maintenance activities.\n",
    "   - Events like \"Routine Check\", \"Engine Repair\" are randomly generated.\n",
    "\n",
    "## 📦 Output\n",
    "\n",
    "Files are saved to Unity Catalog-managed volumes in two separate folders:\n",
    "\n",
    "- `raw_sensor_data_*.csv` → `/Volumes/arao/aerodemo/tmp/raw/`\n",
    "- `maintenance_events_*.csv` → `/Volumes/arao/aerodemo/tmp/maintenance/`\n",
    "\n",
    "Each run creates **timestamped filenames** so that Auto Loader can detect and ingest them as new data.\n",
    "\n",
    "## ✅ Why This Matters\n",
    "\n",
    "This notebook is designed to support:\n",
    "- Continuous ingestion via Auto Loader\n",
    "- Downstream analytics and Delta Live Tables (DLT)\n",
    "- Simulation of realistic aircraft operational behavior\n",
    "\n",
    "> You can re-run this notebook anytime to simulate a new day's worth of data for ingestion and pipeline testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47a1671c-1717-4c47-9adc-8408eb250759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f0a7226-a754-47ea-beca-97e4db6ecfc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Synthetic Aircraft Sensor Data Generator\n",
    "\n",
    "This notebook generates simulated sensor data and maintenance logs for 25 aircraft models over a 1-year period (2024-01-01 to 2024-12-31). Each aircraft experiences:\n",
    "- Gradual wear-and-tear over time (drift in temperature, vibration, and fuel efficiency)\n",
    "- Simulated anomalies and scheduled repairs\n",
    "- Daily readings with a full set of sensor metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4293c9c9-8e87-41c9-bcbe-e3a1062e8bd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_AIRCRAFT_PER_MODEL = 5\n",
    "START_DATE = datetime(2024, 1, 1)\n",
    "END_DATE = datetime(2024, 12, 31)\n",
    "\n",
    "# --- Aircraft Setup ---\n",
    "aircraft_ids = (\n",
    "    [f\"A320_{i:03d}\" for i in range(101, 101 + NUM_AIRCRAFT_PER_MODEL)] +\n",
    "    [f\"B737_{i:03d}\" for i in range(201, 201 + NUM_AIRCRAFT_PER_MODEL)] +\n",
    "    [f\"A330_{i:03d}\" for i in range(301, 301 + NUM_AIRCRAFT_PER_MODEL)] +\n",
    "    [f\"B777_{i:03d}\" for i in range(401, 401 + NUM_AIRCRAFT_PER_MODEL)] +\n",
    "    [f\"E190_{i:03d}\" for i in range(501, 501 + NUM_AIRCRAFT_PER_MODEL)]\n",
    ")\n",
    "\n",
    "models = (\n",
    "    [\"A320\"] * NUM_AIRCRAFT_PER_MODEL +\n",
    "    [\"B737\"] * NUM_AIRCRAFT_PER_MODEL +\n",
    "    [\"A330\"] * NUM_AIRCRAFT_PER_MODEL +\n",
    "    [\"B777\"] * NUM_AIRCRAFT_PER_MODEL +\n",
    "    [\"E190\"] * NUM_AIRCRAFT_PER_MODEL\n",
    ")\n",
    "\n",
    "date_range = [START_DATE + timedelta(days=i) for i in range((END_DATE - START_DATE).days + 1)]\n",
    "raw_data, maintenance_events = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52716e62-e436-4138-a970-67c95d089b41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sensor Data Simulation for Each Aircraft\n",
    "\n",
    "This cell generates synthetic daily sensor readings and maintenance logs for each of the 25 aircraft defined earlier.\n",
    "\n",
    "Key logic:\n",
    "- **Baseline Initialization**: Each aircraft starts with slightly different base values for engine temperature, fuel efficiency, and vibration.\n",
    "- **Drift Simulation**: Over time, performance drifts to simulate aging and wear.\n",
    "- **Scheduled Maintenance**:\n",
    "  - A \"Routine Check\" is injected at a random index between days 150–180.\n",
    "  - An \"Engine Repair\" is scheduled shortly after an artificially injected anomaly.\n",
    "- **Anomaly Injection**: A spike in temperature, drop in fuel efficiency, and sharp increase in vibration is added on a specific day to simulate a high-risk event.\n",
    "- **Post-Repair Reset**: After repairs, sensor readings gradually improve to reflect the effect of maintenance.\n",
    "\n",
    "Metrics simulated daily:\n",
    "- `engine_temp`, `fuel_efficiency`, `vibration`, `altitude`, `airspeed`, `oil_pressure`, `engine_rpm`, and `battery_voltage`.\n",
    "- Each record is time-stamped using the full datetime string (`%Y-%m-%d %H:%M:%S`) to support future time-based operations.\n",
    "\n",
    "All generated data is stored in:\n",
    "- `raw_data`: Daily sensor readings\n",
    "- `maintenance_events`: Log of maintenance activities\n",
    "\n",
    "This setup provides a realistic dataset for building and testing predictive maintenance workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef48d2c6-bd3a-4a10-a1e1-7f65a1b260d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import time, datetime\n",
    "\n",
    "# Generate data for each aircraft\n",
    "for aircraft_id, model in zip(aircraft_ids, models):\n",
    "    # Initialize base sensor values\n",
    "    base_temp = random.uniform(550, 600)\n",
    "    base_fuel_eff = random.uniform(80, 90)\n",
    "    base_vib = random.uniform(3.0, 6.0)\n",
    "\n",
    "    # Simulate daily drift (wear and tear)\n",
    "    drift_temp = random.uniform(0.05, 0.1)\n",
    "    drift_fuel_eff = random.uniform(-0.1, -0.05)\n",
    "    drift_vib = random.uniform(0.01, 0.03)\n",
    "\n",
    "    # Schedule maintenance and anomaly windows\n",
    "    sched_idx = random.randint(150, 180)\n",
    "    anomaly_idx = random.randint(250, 300)\n",
    "    if anomaly_idx <= sched_idx:\n",
    "        anomaly_idx = sched_idx + 50\n",
    "    if anomaly_idx >= len(date_range):\n",
    "        anomaly_idx = len(date_range) - 60\n",
    "    repair_idx = min(anomaly_idx + 1, len(date_range) - 1)\n",
    "\n",
    "    # Add maintenance events\n",
    "    maintenance_events.append({\n",
    "        \"aircraft_id\": aircraft_id,\n",
    "        \"event_date\": date_range[sched_idx].date(),\n",
    "        \"event_type\": \"Routine Check\"\n",
    "    })\n",
    "    maintenance_events.append({\n",
    "        \"aircraft_id\": aircraft_id,\n",
    "        \"event_date\": date_range[repair_idx].date(),\n",
    "        \"event_type\": \"Engine Repair\"\n",
    "    })\n",
    "\n",
    "    # Generate one record per day with randomized timestamp\n",
    "    for day_idx, current_date in enumerate(date_range):\n",
    "        # Add randomized time-of-day to the current date\n",
    "        hour = random.randint(0, 23)\n",
    "        minute = random.randint(0, 59)\n",
    "        second = random.randint(0, 59)\n",
    "        timestamp = datetime.combine(current_date, time(hour, minute, second))\n",
    "\n",
    "        # Sensor drift and noise\n",
    "        engine_temp = base_temp + drift_temp * day_idx + np.random.normal(0, 2)\n",
    "        fuel_eff = base_fuel_eff + drift_fuel_eff * day_idx + np.random.normal(0, 1)\n",
    "        vibration = base_vib + drift_vib * day_idx + np.random.normal(0, 0.1)\n",
    "\n",
    "        # Additional sensor values\n",
    "        altitude = 30000 + np.random.normal(0, 500)\n",
    "        airspeed = 450 + np.random.normal(0, 20)\n",
    "        oil_pressure = round(random.uniform(30, 90), 2)\n",
    "        engine_rpm = int(random.uniform(1500, 5000))\n",
    "        battery_voltage = round(random.uniform(22.0, 28.0), 2)\n",
    "\n",
    "        # Inject anomaly on specific day\n",
    "        anomaly_score = 0.0\n",
    "        if day_idx == anomaly_idx:\n",
    "            engine_temp *= 1.3\n",
    "            fuel_eff *= 0.7\n",
    "            vibration = max(vibration * 3, vibration + 5)\n",
    "            anomaly_score = 1.0\n",
    "\n",
    "        # Post-repair normalization\n",
    "        if day_idx >= repair_idx:\n",
    "            engine_temp = max(base_temp, engine_temp - 0.15 * base_temp)\n",
    "            fuel_eff = min(base_fuel_eff, fuel_eff + 0.15 * base_fuel_eff)\n",
    "            vibration = max(0.0, vibration - 0.5 * base_vib)\n",
    "\n",
    "        # Append the record to raw_data\n",
    "        raw_data.append({\n",
    "            \"timestamp\": timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"aircraft_id\": aircraft_id,\n",
    "            \"model\": model,\n",
    "            \"engine_temp\": round(engine_temp, 2),\n",
    "            \"fuel_efficiency\": round(fuel_eff, 2),\n",
    "            \"vibration\": round(vibration, 3),\n",
    "            \"altitude\": round(altitude, 2),\n",
    "            \"airspeed\": round(airspeed, 2),\n",
    "            \"anomaly_score\": anomaly_score,\n",
    "            \"oil_pressure\": oil_pressure,\n",
    "            \"engine_rpm\": engine_rpm,\n",
    "            \"battery_voltage\": battery_voltage\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72c9a8fd-2688-478a-a3d5-e94e72f72119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print sample and sizes for verification\n",
    "# print(\"Sensor records:\", len(raw_data))\n",
    "# print(\"Maintenance events:\", len(maintenance_events))\n",
    "# print(pd.DataFrame(raw_data).head())\n",
    "# print(pd.DataFrame(maintenance_events).head())\n",
    "print(pd.DataFrame(raw_data).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b92a19-0690-40fb-91c7-2199dade5a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "📦 Benefits of the logic in the next cell:\n",
    "- \t✅ Keeps ingestion folders clean\n",
    "- \t✅ Prevents Auto Loader schema collisions\n",
    "- \t✅ Aligned with your 03_ and 03B_ setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f63a924d-a02e-4693-91f9-f4c0d45861d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Define output directories (volume paths)\n",
    "raw_data_path = \"/Volumes/arao/aerodemo/tmp/raw\"\n",
    "maint_data_path = \"/Volumes/arao/aerodemo/tmp/maintenance\"\n",
    "\n",
    "# Generate timestamp string for filenames\n",
    "timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Construct full file paths\n",
    "raw_file_path = f\"{raw_data_path}/raw_sensor_data_{timestamp_str}.csv\"\n",
    "maint_file_path = f\"{maint_data_path}/maintenance_events_{timestamp_str}.csv\"\n",
    "\n",
    "# Save raw sensor data\n",
    "pd.DataFrame(raw_data, columns=[\n",
    "    \"timestamp\", \"aircraft_id\", \"model\", \n",
    "    \"engine_temp\", \"fuel_efficiency\", \"vibration\",\n",
    "    \"altitude\", \"airspeed\", \"anomaly_score\",\n",
    "    \"oil_pressure\", \"engine_rpm\", \"battery_voltage\"\n",
    "]).to_csv(raw_file_path, index=False)\n",
    "\n",
    "# Save maintenance event data\n",
    "pd.DataFrame(maintenance_events, columns=[\n",
    "    \"aircraft_id\", \"event_date\", \"event_type\"\n",
    "]).to_csv(maint_file_path, index=False)\n",
    "\n",
    "print(\"✅ Files written:\")\n",
    "print(f\"- {raw_file_path}\")\n",
    "print(f\"- {maint_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19407c41-9ab6-4bd0-b264-dbba582733d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ✈️ Aircraft Model Reference Table (for Digital Twin Mapping)\n",
    "\n",
    "This section generates a static reference table called `aircraft_model_reference`, which contains key specifications for each aircraft model (e.g., manufacturer, engine type, seating capacity, and range). This table acts as foundational metadata for building Digital Twin representations and linking operational data to aircraft characteristics.\n",
    "\n",
    "The table is stored as a Delta table in Unity Catalog under `arao.aerodemo.aircraft_model_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8e582e6-d4bd-47a9-be17-1ed56dddc193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define model-level reference data\n",
    "model_data = [\n",
    "    (\"A320\", \"Airbus\", \"CFM56\", 180, 6150),\n",
    "    (\"B737\", \"Boeing\", \"LEAP-1B\", 160, 5600),\n",
    "    (\"A330\", \"Airbus\", \"Trent 700\", 277, 13450)\n",
    "]\n",
    "\n",
    "columns = [\"model\", \"manufacturer\", \"engine_type\", \"capacity\", \"range_km\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_model = spark.createDataFrame(model_data, columns)\n",
    "\n",
    "# Check schema\n",
    "df_model.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "df_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb24412c-fa4e-48a8-89e1-4153003ce8c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define model-level reference data\n",
    "model_data = [\n",
    "    (\"A320\", \"Airbus\", \"CFM56\", 180, 6150),\n",
    "    (\"B737\", \"Boeing\", \"LEAP-1B\", 160, 5600),\n",
    "    (\"A330\", \"Airbus\", \"Trent 700\", 277, 13450)\n",
    "]\n",
    "\n",
    "columns = [\"model\", \"manufacturer\", \"engine_type\", \"capacity\", \"range_km\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_model = spark.createDataFrame(model_data, columns)\n",
    "\n",
    "# Cast numerical columns to IntegerType to match Delta table definition\n",
    "df_model = df_model.withColumn(\"capacity\", df_model[\"capacity\"].cast(IntegerType()))\n",
    "df_model = df_model.withColumn(\"range_km\", df_model[\"range_km\"].cast(IntegerType()))\n",
    "\n",
    "# Overwrite table\n",
    "df_model.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"arao.aerodemo.aircraft_model_reference\")\n",
    "\n",
    "print(\"✅ Aircraft model reference table written with correct schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03dde774-9a02-4f68-8d01-156538a3fca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🔧 Engine Twin Data\n",
    "\n",
    "This cell generates synthetic data for engine components associated with aircraft.\n",
    "It simulates sensor readings and metadata for predictive analysis:\n",
    "- `thrust_level` (kN)\n",
    "- `fuel_consumption_rate` (liters/hr)\n",
    "- `temperature_reading` (°C)\n",
    "- `vibration_level` (g-force)\n",
    "- `oil_pressure` (psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2613c8-91e2-496d-9d21-7c45258a18b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_engines_data(num_records_per_aircraft=100):\n",
    "    aircraft_ids = [\"A320_101\", \"A330_201\", \"B737_301\"]\n",
    "    data = {\n",
    "        'engine_id': [],\n",
    "        'aircraft_id': [],\n",
    "        'event_timestamp': [],\n",
    "        'thrust_level': [],\n",
    "        'fuel_consumption_rate': [],\n",
    "        'temperature_reading': [],\n",
    "        'vibration_level': [],\n",
    "        'oil_pressure': []\n",
    "    }\n",
    "\n",
    "    for aircraft_id in aircraft_ids:\n",
    "        for i in range(num_records_per_aircraft):\n",
    "            random_days_ago = random.randint(0, 6)\n",
    "            random_time = datetime.now() - timedelta(days=random_days_ago, hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "            data['engine_id'].append(f'ENG_{aircraft_id}_{i:03d}')  # zero-padded for uniqueness\n",
    "            data['aircraft_id'].append(aircraft_id)\n",
    "            data['event_timestamp'].append(random_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data['thrust_level'].append(round(np.random.uniform(50000, 120000), 2))\n",
    "            data['fuel_consumption_rate'].append(round(np.random.uniform(2.0, 5.0), 3))\n",
    "            data['temperature_reading'].append(round(np.random.uniform(300, 800), 2))\n",
    "            data['vibration_level'].append(round(np.random.uniform(0.1, 2.0), 3))\n",
    "            data['oil_pressure'].append(round(np.random.uniform(30, 80), 2))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate DataFrame\n",
    "df = generate_engines_data()\n",
    "\n",
    "# Save to Auto Loader-compatible path\n",
    "output_path = \"/Volumes/arao/aerodemo/tmp/engine\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = f\"{output_path}/engines_sample.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)  # safely remove old file\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Engine data generated: {len(df)} rows saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddc53576-44d5-4ab3-a793-4e9fe3cd77a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🛞 Landing Gear Twin Data\n",
    "\n",
    "Simulates operational data for landing gear systems including:\n",
    "- `hydraulic_pressure` (psi)\n",
    "- `strut_compression` (cm)\n",
    "- `brake_wear` (%)\n",
    "- `brake_temperature` (°C)\n",
    "- `shock_absorber_status` (%)\n",
    "\n",
    "\n",
    "Target folder: `/Volumes/arao/aerodemo/tmp/landing_gear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06edf4c2-1bae-49f9-8d18-cd6173b6d62d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_landing_gear_data(num_records_per_aircraft=100):\n",
    "    aircraft_ids = [\"A320_101\", \"A330_201\", \"B737_301\"]\n",
    "    data = {\n",
    "        'gear_id': [],\n",
    "        'aircraft_id': [],\n",
    "        'event_timestamp': [],\n",
    "        'hydraulic_pressure': [],\n",
    "        'strut_compression': [],\n",
    "        'brake_wear': [],\n",
    "        'brake_temperature': [],\n",
    "        'shock_absorber_status': []\n",
    "    }\n",
    "\n",
    "    for aircraft_id in aircraft_ids:\n",
    "        for i in range(num_records_per_aircraft):\n",
    "            random_days_ago = random.randint(0, 6)\n",
    "            random_time = datetime.now() - timedelta(days=random_days_ago, hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "            data['gear_id'].append(f'GEAR_{aircraft_id}_{i:03d}')  # zero-padded ID\n",
    "            data['aircraft_id'].append(aircraft_id)\n",
    "            data['event_timestamp'].append(random_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data['hydraulic_pressure'].append(round(np.random.uniform(2500, 3000), 2))\n",
    "            data['strut_compression'].append(round(np.random.uniform(5, 15), 2))\n",
    "            data['brake_wear'].append(round(np.random.uniform(0, 100), 2))\n",
    "            data['brake_temperature'].append(round(np.random.uniform(200, 500), 2))\n",
    "            data['shock_absorber_status'].append(round(np.random.uniform(60, 100), 2))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate DataFrame\n",
    "df = generate_landing_gear_data()\n",
    "\n",
    "# Save to Auto Loader-compatible path\n",
    "output_path = \"/Volumes/arao/aerodemo/tmp/landing_gear\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = f\"{output_path}/landing_gear_sample.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)  # safely remove old file\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Landing gear data generated: {len(df)} rows saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1acb4e70-9900-42c1-bae5-125e3588566c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🧭 Avionics Twin Data\n",
    "\n",
    "Generates synthetic telemetry data for avionics systems including:\n",
    "- `power_status` (volts)\n",
    "- `signal_integrity` (dB)\n",
    "- `data_transmission_rate` (Mbps)\n",
    "- `system_temperature` (°C)\n",
    "- `error_logs` (count)\n",
    "\n",
    "Target folder: `/Volumes/arao/aerodemo/tmp/avionics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bb4ff6-ca48-4a36-b405-50e5e39fd418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_avionics_data(num_records_per_aircraft=100):\n",
    "    aircraft_ids = [\"A320_101\", \"A330_201\", \"B737_301\"]\n",
    "    data = {\n",
    "        'avionics_id': [],\n",
    "        'aircraft_id': [],\n",
    "        'event_timestamp': [],\n",
    "        'power_status': [],\n",
    "        'signal_integrity': [],\n",
    "        'data_transmission_rate': [],\n",
    "        'system_temperature': [],\n",
    "        'error_logs': []\n",
    "    }\n",
    "\n",
    "    for aircraft_id in aircraft_ids:\n",
    "        for i in range(num_records_per_aircraft):\n",
    "            random_days_ago = random.randint(0, 6)\n",
    "            random_time = datetime.now() - timedelta(days=random_days_ago, hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "            data['avionics_id'].append(f'AVN_{aircraft_id}_{i:03d}')  # zero-padded ID\n",
    "            data['aircraft_id'].append(aircraft_id)\n",
    "            data['event_timestamp'].append(random_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data['power_status'].append(round(np.random.uniform(110, 130), 2))\n",
    "            data['signal_integrity'].append(round(np.random.uniform(20, 40), 2))\n",
    "            data['data_transmission_rate'].append(round(np.random.uniform(50, 100), 2))\n",
    "            data['system_temperature'].append(round(np.random.uniform(20, 50), 2))\n",
    "            data['error_logs'].append(np.random.randint(0, 10))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate DataFrame\n",
    "df = generate_avionics_data()\n",
    "\n",
    "# Save to Auto Loader-compatible path\n",
    "output_path = \"/Volumes/arao/aerodemo/tmp/avionics\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = f\"{output_path}/avionics_sample.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)  # safely remove old file\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Avionics data generated: {len(df)} rows saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4b8176b-c15d-48fc-af30-afa29788db8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🌬️ Cabin Pressurization Twin Data\n",
    "\n",
    "Simulates environmental control data for cabin pressure systems:\n",
    "- `cabin_pressure` (psi)\n",
    "- `seal_integrity` (%)\n",
    "- `airflow_rate` (CFM)\n",
    "- `temperature_control` (°C)\n",
    "- `humidity_level` (%)\n",
    "\n",
    "Target folder: `/Volumes/arao/aerodemo/tmp/cabin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d514a79a-77b5-40c9-a65c-8e5152895ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_cabin_pressurization_data(num_records_per_aircraft=100):\n",
    "    aircraft_ids = [\"A320_101\", \"A330_201\", \"B737_301\"]\n",
    "    data = {\n",
    "        'cabin_id': [],\n",
    "        'aircraft_id': [],\n",
    "        'event_timestamp': [],\n",
    "        'cabin_pressure': [],\n",
    "        'seal_integrity': [],\n",
    "        'airflow_rate': [],\n",
    "        'temperature_control': [],\n",
    "        'humidity_level': []\n",
    "    }\n",
    "\n",
    "    for aircraft_id in aircraft_ids:\n",
    "        for i in range(num_records_per_aircraft):\n",
    "            random_days_ago = random.randint(0, 6)\n",
    "            random_time = datetime.now() - timedelta(days=random_days_ago, hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "            data['cabin_id'].append(f'CAB_{aircraft_id}_{i:03d}')  # zero-padded\n",
    "            data['aircraft_id'].append(aircraft_id)\n",
    "            data['event_timestamp'].append(random_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data['cabin_pressure'].append(round(np.random.uniform(10, 15), 2))\n",
    "            data['seal_integrity'].append(round(np.random.uniform(90, 100), 2))\n",
    "            data['airflow_rate'].append(round(np.random.uniform(300, 500), 2))\n",
    "            data['temperature_control'].append(round(np.random.uniform(18, 25), 2))\n",
    "            data['humidity_level'].append(round(np.random.uniform(20, 60), 2))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate DataFrame\n",
    "df = generate_cabin_pressurization_data()\n",
    "\n",
    "# Save to Auto Loader-compatible path\n",
    "output_path = \"/Volumes/arao/aerodemo/tmp/cabin\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = f\"{output_path}/cabin_pressurization_sample.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)  # safely overwrite old file\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Cabin Pressurization data generated: {len(df)} rows saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cc22842-9963-484a-82dc-0715fcb67989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🛩️ Airframe Synthetic Data Generation: Airframe\n",
    "\n",
    "\n",
    "Generates synthetic structural health data for airframe monitoring:\n",
    "- `stress_points` (MPa)\n",
    "- `fatigue_crack_growth` (mm)\n",
    "- `temperature_fluctuations` (°C)\n",
    "- `structural_integrity` (score %)\n",
    "\n",
    "Target folder: `/Volumes/arao/aerodemo/tmp/airframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d524bfd-025d-41e3-a974-fef1a5436ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_airframe_data(num_records_per_aircraft=100):\n",
    "    aircraft_ids = [\"A320_101\", \"A330_201\", \"B737_301\"]\n",
    "    data = {\n",
    "        'airframe_id': [],\n",
    "        'aircraft_id': [],\n",
    "        'event_timestamp': [],\n",
    "        'stress_points': [],\n",
    "        'fatigue_crack_growth': [],\n",
    "        'temperature_fluctuations': [],\n",
    "        'structural_integrity': []\n",
    "    }\n",
    "\n",
    "    for aircraft_id in aircraft_ids:\n",
    "        for i in range(num_records_per_aircraft):\n",
    "            random_days_ago = random.randint(0, 6)\n",
    "            random_time = datetime.now() - timedelta(days=random_days_ago, hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "            data['airframe_id'].append(f'AFRAME_{aircraft_id}_{i:03d}')  # zero-padded\n",
    "            data['aircraft_id'].append(aircraft_id)\n",
    "            data['event_timestamp'].append(random_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data['stress_points'].append(round(np.random.uniform(100, 300), 2))\n",
    "            data['fatigue_crack_growth'].append(round(np.random.uniform(0, 10), 2))\n",
    "            data['temperature_fluctuations'].append(round(np.random.uniform(-30, 50), 2))\n",
    "            data['structural_integrity'].append(round(np.random.uniform(50, 100), 2))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate DataFrame\n",
    "df = generate_airframe_data()\n",
    "\n",
    "# Save to Auto Loader-compatible path\n",
    "output_path = \"/Volumes/arao/aerodemo/tmp/airframe\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = f\"{output_path}/airframe_sample.csv\"\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)  # safely overwrite old file\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Airframe data generated: {len(df)} rows saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbd33787-508a-4b09-b203-21c25525acab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ✅ Sanity Check Script for All Component Datasets\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "def sanity_check(df, name):\n",
    "    print(f\"\\n📦 Checking: {name}\")\n",
    "    print(f\"• Row count: {df.count()}\")\n",
    "    \n",
    "    print(\"• Null checks:\")\n",
    "    df.select([\n",
    "        count(when(col(c).isNull(), c)).alias(f\"{c}_nulls\") for c in df.columns\n",
    "    ]).show(truncate=False)\n",
    "    \n",
    "    print(\"• Sample data:\")\n",
    "    df.show(5, truncate=False)\n",
    "\n",
    "# ---- 1. engine ----\n",
    "engine_schema = StructType([\n",
    "    StructField(\"engine_id\", StringType()),\n",
    "    StructField(\"aircraft_id\", StringType()),\n",
    "    StructField(\"event_timestamp\", StringType()),\n",
    "    StructField(\"thrust_level\", DoubleType()),\n",
    "    StructField(\"fuel_consumption_rate\", DoubleType()),\n",
    "    StructField(\"temperature_reading\", DoubleType()),\n",
    "    StructField(\"vibration_level\", DoubleType()),\n",
    "    StructField(\"oil_pressure\", DoubleType())\n",
    "])\n",
    "engine_df = spark.read.option(\"header\", True).schema(engine_schema).csv(\"/Volumes/arao/aerodemo/tmp/engine\")\n",
    "sanity_check(engine_df, \"engine\")\n",
    "\n",
    "# ---- 2. landing_gear ----\n",
    "landing_gear_schema = StructType([\n",
    "    StructField(\"gear_id\", StringType()),\n",
    "    StructField(\"aircraft_id\", StringType()),\n",
    "    StructField(\"event_timestamp\", StringType()),\n",
    "    StructField(\"hydraulic_pressure\", DoubleType()),\n",
    "    StructField(\"strut_compression\", DoubleType()),\n",
    "    StructField(\"brake_wear\", DoubleType()),\n",
    "    StructField(\"brake_temperature\", DoubleType()),\n",
    "    StructField(\"shock_absorber_status\", DoubleType())\n",
    "])\n",
    "landing_gear_df = spark.read.option(\"header\", True).schema(landing_gear_schema).csv(\"/Volumes/arao/aerodemo/tmp/landing_gear\")\n",
    "sanity_check(landing_gear_df, \"landing_gear\")\n",
    "\n",
    "# ---- 3. avionics ----\n",
    "avionics_schema = StructType([\n",
    "    StructField(\"avionics_id\", StringType()),\n",
    "    StructField(\"aircraft_id\", StringType()),\n",
    "    StructField(\"event_timestamp\", StringType()),\n",
    "    StructField(\"power_status\", DoubleType()),\n",
    "    StructField(\"signal_integrity\", DoubleType()),\n",
    "    StructField(\"data_transmission_rate\", DoubleType()),\n",
    "    StructField(\"system_temperature\", DoubleType()),\n",
    "    StructField(\"error_logs\", IntegerType())\n",
    "])\n",
    "avionics_df = spark.read.option(\"header\", True).schema(avionics_schema).csv(\"/Volumes/arao/aerodemo/tmp/avionics\")\n",
    "sanity_check(avionics_df, \"avionics_systems\")\n",
    "\n",
    "# ---- 4. cabin_pressurization ----\n",
    "cabin_schema = StructType([\n",
    "    StructField(\"cabin_id\", StringType()),\n",
    "    StructField(\"aircraft_id\", StringType()),\n",
    "    StructField(\"event_timestamp\", StringType()),\n",
    "    StructField(\"cabin_pressure\", DoubleType()),\n",
    "    StructField(\"seal_integrity\", DoubleType()),\n",
    "    StructField(\"airflow_rate\", DoubleType()),\n",
    "    StructField(\"temperature_control\", DoubleType()),\n",
    "    StructField(\"humidity_level\", DoubleType())\n",
    "])\n",
    "cabin_df = spark.read.option(\"header\", True).schema(cabin_schema).csv(\"/Volumes/arao/aerodemo/tmp/cabin\")\n",
    "sanity_check(cabin_df, \"cabin_pressurization\")\n",
    "\n",
    "# ---- 5. airframe ----\n",
    "airframe_schema = StructType([\n",
    "    StructField(\"airframe_id\", StringType()),\n",
    "    StructField(\"aircraft_id\", StringType()),\n",
    "    StructField(\"event_timestamp\", StringType()),\n",
    "    StructField(\"stress_points\", DoubleType()),\n",
    "    StructField(\"fatigue_crack_growth\", DoubleType()),\n",
    "    StructField(\"temperature_fluctuations\", DoubleType()),\n",
    "    StructField(\"structural_integrity\", DoubleType())\n",
    "])\n",
    "airframe_df = spark.read.option(\"header\", True).schema(airframe_schema).csv(\"/Volumes/arao/aerodemo/tmp/airframe\")\n",
    "sanity_check(airframe_df, \"airframe\")\n",
    "\n",
    "print(\"\\n✅ All sanity checks completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02_Synthetic_Data_Generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
