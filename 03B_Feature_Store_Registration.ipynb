{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e65706f4-8ace-4a01-bcb6-9396430eacc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìò Feature Store Registration\n",
    "This notebook registers the engineered sensor features table from the Delta Live Tables (DLT) pipeline\n",
    "into the Databricks Feature Store for easier discoverability, governance, and reuse during model training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99ef2322-e30b-4b5d-94f6-1ef5ca86a760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.table(\"arao.aerodemo.sensor_features\").cache()\n",
    "# df.count()  # Force materialization to avoid lazy read error\n",
    "# df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"arao.aerodemo.sensor_features_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d2316e-6446-4489-9ff5-ed7cefe80f1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "# ALTER COLUMN aircraft_id SET NOT NULL;\n",
    "\n",
    "# ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "# ALTER COLUMN timestamp SET NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "538bf290-962b-4eb6-9b97-4bfb4dc5c51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "# ADD CONSTRAINT sensor_features_pk \n",
    "# PRIMARY KEY (aircraft_id, timestamp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5f8457b-4791-482b-966c-7260fda04a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# ALTER TABLE arao.aerodemo.sensor_features\n",
    "# ADD CONSTRAINT sensor_features_pk PRIMARY KEY (aircraft_id, timestamp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d561261-5fcc-4d14-8625-1c3208d48464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# üßπ 1. Drop the old table if it exists to avoid constraint conflicts\n",
    "spark.sql(\"DROP TABLE IF EXISTS arao.aerodemo.sensor_features_table\")\n",
    "\n",
    "# üì• 2. Read from existing DLT materialized table\n",
    "df_raw = spark.table(\"arao.aerodemo.sensor_features\") \\\n",
    "    .filter(\"aircraft_id IS NOT NULL AND timestamp IS NOT NULL\")\n",
    "\n",
    "# üßº 3. Clean nulls (as double safety) and cast PKs\n",
    "df_clean = df_raw.withColumn(\"aircraft_id\", F.col(\"aircraft_id\").cast(\"string\")) \\\n",
    "                 .withColumn(\"timestamp\", F.col(\"timestamp\").cast(\"string\"))\n",
    "\n",
    "# üíæ 4. Save as Delta table with schema overwrite\n",
    "df_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"arao.aerodemo.sensor_features_table\")\n",
    "\n",
    "# üîê 5. Enforce NOT NULL constraints\n",
    "spark.sql(\"\"\"\n",
    "  ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "  ALTER COLUMN aircraft_id SET NOT NULL\n",
    "\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "  ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "  ALTER COLUMN timestamp SET NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# üõ°Ô∏è 6. Add primary key constraint (required for Feature Store)\n",
    "spark.sql(\"\"\"\n",
    "  ALTER TABLE arao.aerodemo.sensor_features_table \n",
    "  ADD CONSTRAINT sensor_features_pk \n",
    "  PRIMARY KEY (aircraft_id, timestamp)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7da20af2-fbc3-4517-b227-3ee890d3d5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "fs.create_table(\n",
    "    name=\"arao.aerodemo.sensor_features_table\",\n",
    "    primary_keys=[\"aircraft_id\", \"timestamp\"],\n",
    "    timestamp_keys=[\"timestamp\"],\n",
    "    description=\"Engineered features for anomaly prediction from sensor data\",\n",
    "    df=spark.read.table(\"arao.aerodemo.sensor_features_table\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03B_Feature_Store_Registration",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
