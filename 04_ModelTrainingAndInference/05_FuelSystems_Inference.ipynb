{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4185271-d908-4f3f-9c8a-f571d63b7b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìà 05_Model_Inference.ipynb\n",
    "\n",
    "This notebook demonstrates how to use the trained and registered aircraft anomaly prediction model for inference.\n",
    "\n",
    "It covers:\n",
    "- Loading the model using both version number and alias (recommended)\n",
    "- Predicting anomaly likelihood on new sensor feature data\n",
    "- Writing high-risk predictions to the `anomaly_alerts` Delta table\n",
    "\n",
    "This ensures the end-to-end machine learning lifecycle is complete from training to real-time scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "204625d1-e25c-4f76-8abf-0a8be735dc71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.pyfunc import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae9d94c5-cee6-4b05-b08f-da0e6bcf7a7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üî¢ Load model using version number\n",
    "\n",
    "This method explicitly loads a specific version of the model registered in Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29143dc8-f614-4341-9b7e-e41052081cee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = \"models:/arao.aerodemo.aircraftanomalypredictor@champion\"\n",
    "loaded_model = load_model(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c3288f6-430e-4bcd-8cf8-4f6c458e8a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üè∑Ô∏è Load model using alias\n",
    "\n",
    "This preferred method loads the model tagged with the alias `champion`, making it easy to switch versions without code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e730f1-71c2-4dcd-99c6-803a50af14eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri_alias = \"models:/AircraftAnomalyPredictor@champion\"\n",
    "model_champion = mlflow.pyfunc.load_model(model_uri_alias)\n",
    "print(\"‚úÖ Loaded model with alias @champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c7b98cb-ef5a-4f56-ad88-08fd2138a4e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß™ Prepare input features for prediction\n",
    "\n",
    "The sample below must match the schema used during model training, including the engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "148e40fe-6588-473c-ba9c-e1a6d8124bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_df = spark.read.table(\"arao.aerodemo.sensor_features_table\").toPandas()\n",
    "\n",
    "# Drop label column and cast to match model schema\n",
    "batch_df = feature_df.drop(columns=[\"anomaly_score\"]).sample(5)\n",
    "batch_df = batch_df.astype({\n",
    "    \"engine_temp\": \"float64\",\n",
    "    \"fuel_efficiency\": \"float64\",\n",
    "    \"vibration\": \"float64\",\n",
    "    \"altitude\": \"float64\",\n",
    "    \"airspeed\": \"float64\",\n",
    "    \"oil_pressure\": \"float64\",\n",
    "    \"engine_rpm\": \"int32\",\n",
    "    \"battery_voltage\": \"float64\",\n",
    "    \"prev_anomaly\": \"float64\",\n",
    "    \"avg_engine_temp_7d\": \"float64\",\n",
    "    \"avg_vibration_7d\": \"float64\",\n",
    "    \"avg_rpm_7d\": \"float64\",\n",
    "    \"days_since_maint\": \"float64\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f26df553-e0bb-4d02-83a6-7055db89c256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîç Run inference using the Registered Model Version\n",
    "\n",
    "This cell runs inference using a **specific registered model version** (`version 2`) from Unity Catalog.\n",
    "Using version numbers is useful when you want full control over which model version to use, especially for repeatable experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7506e2c-c527-48fd-b7b8-5184a4b34555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.pyfunc import load_model\n",
    "\n",
    "# üî¢ Specify the exact model version\n",
    "model_uri = \"models:/arao.aerodemo.aircraftanomalypredictor/3\"\n",
    "loaded_model = load_model(model_uri)\n",
    "\n",
    "# üß™ Sample input matching model signature\n",
    "sample_input = pd.DataFrame([{\n",
    "    \"engine_temp\": 610.0,\n",
    "    \"fuel_efficiency\": 76.2,\n",
    "    \"vibration\": 5.3,\n",
    "    \"altitude\": 29950.0,\n",
    "    \"airspeed\": 452.0,\n",
    "    \"oil_pressure\": 61.0,\n",
    "    \"engine_rpm\": np.int32(3900),\n",
    "    \"battery_voltage\": 25.0,\n",
    "    \"prev_anomaly\": 1.0,\n",
    "    \"avg_engine_temp_7d\": 608.0,\n",
    "    \"avg_vibration_7d\": 5.0,\n",
    "    \"avg_rpm_7d\": 3850.0,\n",
    "    \"days_since_maint\": 12.0\n",
    "}])\n",
    "\n",
    "# üß† Predict\n",
    "prediction = loaded_model.predict(sample_input)\n",
    "print(\"üß† Predicted Anomaly (0 = Normal, 1 = Anomalous):\", prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cd5a6a3-a733-4ee7-a3a6-3d9a7660e9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîç Run inference using the `@champion` alias\n",
    "\n",
    "This ensures you're scoring with the most recently promoted model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc77a90-5d00-4beb-8265-ba8abe653668",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(batch_df)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56cba54-ffa7-4c3e-83f1-b8b435c47f61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üíæ Save inference results to Delta table\n",
    "\n",
    "This allows downstream applications or alerts to monitor high-risk events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8531e547-4bc8-4707-982e-9e57096944c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.pyfunc import load_model\n",
    "\n",
    "# ‚úÖ Load the champion version of the model\n",
    "model_uri = \"models:/arao.aerodemo.aircraftanomalypredictor@champion\"\n",
    "loaded_model = load_model(model_uri)\n",
    "\n",
    "# üîç Run inference\n",
    "predictions = loaded_model.predict(batch_df)\n",
    "\n",
    "# ‚úÖ Attach predictions and write back to Delta table\n",
    "inference_df = batch_df.copy()\n",
    "inference_df[\"predicted_anomaly\"] = predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b549ae7-0e6a-407f-b8a5-a91ee74c39ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759f23e1-5e99-46e4-af28-742f5855213d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, current_date, lit\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark_df = spark.createDataFrame(inference_df)\n",
    "\n",
    "# ‚úÖ Align schema types\n",
    "\n",
    "# 1Ô∏è‚É£ Cast 'timestamp' from string to timestamp type\n",
    "spark_df = spark_df.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "\n",
    "# 2Ô∏è‚É£ Cast numeric fields to match target table\n",
    "spark_df = spark_df.withColumn(\"capacity\", col(\"capacity\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"range_km\", col(\"range_km\").cast(\"int\"))\n",
    "spark_df = spark_df.withColumn(\"days_since_maint\", col(\"days_since_maint\").cast(\"int\"))\n",
    "\n",
    "# 3Ô∏è‚É£ Add missing columns with default values if they don‚Äôt exist\n",
    "if \"alert_day\" not in spark_df.columns:\n",
    "    spark_df = spark_df.withColumn(\"alert_day\", current_date())\n",
    "\n",
    "if \"batch_id\" not in spark_df.columns:\n",
    "    spark_df = spark_df.withColumn(\"batch_id\", lit(\"batch_001\"))\n",
    "\n",
    "if \"anomaly_score\" not in spark_df.columns:\n",
    "    spark_df = spark_df.withColumn(\"anomaly_score\", lit(None).cast(\"int\"))\n",
    "\n",
    "# ‚úÖ Write to Delta table\n",
    "spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"arao.aerodemo.anomaly_alerts\")\n",
    "\n",
    "print(\"‚úÖ Inference results written to 'arao.aerodemo.anomaly_alerts' Delta table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3322ae31-5231-46c8-ad40-fa8454f86648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "05_Model_Inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
