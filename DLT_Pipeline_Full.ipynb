{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c912e2d0-54e9-4ea8-b78c-c1f762865efd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ”¹ Raw Sensor Data Ingestion\n",
    "\n",
    "This DLT table ingests streaming CSV files of raw aircraft sensor data using Auto Loader.\n",
    "The schema includes:\n",
    "- `timestamp`, `aircraft_id`, `model`\n",
    "- Sensor metrics like `engine_temp`, `fuel_efficiency`, `vibration`, `altitude`, `airspeed`, and `anomaly_score`.\n",
    "\n",
    "Files are read from a managed volume at `/Volumes/arao/aerodemo/tmp/raw`.\n",
    "\n",
    "âœ… **DLT Benefits**:\n",
    "- Built-in schema enforcement\n",
    "- Automatic lineage\n",
    "- Continuous ingestion readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f919c9-4b41-4f2d-b457-1562a3a01f27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define the schema\n",
    "sensor_schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"aircraft_id\", StringType(), True),\n",
    "    StructField(\"model\", StringType(), True),\n",
    "    StructField(\"engine_temp\", DoubleType(), True),\n",
    "    StructField(\"fuel_efficiency\", DoubleType(), True),\n",
    "    StructField(\"vibration\", DoubleType(), True),\n",
    "    StructField(\"altitude\", DoubleType(), True),\n",
    "    StructField(\"airspeed\", DoubleType(), True),\n",
    "    StructField(\"anomaly_score\", DoubleType(), True),\n",
    "    StructField(\"oil_pressure\", DoubleType(), True),\n",
    "    StructField(\"engine_rpm\", IntegerType(), True),\n",
    "    StructField(\"battery_voltage\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"raw_sensor_data\",\n",
    "    comment=\"Ingested raw sensor data from CSVs in mounted volume\"\n",
    ")\n",
    "def load_raw_sensor_data():\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"pathGlobFilter\", \"*.csv\")\n",
    "        .option(\"cloudFiles.schemaLocation\", \"/Volumes/arao/aerodemo/tmp/raw/schema/raw_sensor_data_v2\")\n",
    "        .schema(sensor_schema)\n",
    "        .load(\"/Volumes/arao/aerodemo/tmp/raw\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85992bed-478e-4f95-9d19-e5839d8b2397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ”¹ Maintenance Events Ingestion\n",
    "\n",
    "This DLT table loads structured maintenance event logs for aircraft.\n",
    "Schema includes:\n",
    "- `aircraft_id`, `event_date`, `event_type` (e.g., \"Routine Check\", \"Engine Repair\")\n",
    "\n",
    "Source files are CSVs dropped in `/Volumes/arao/aerodemo/tmp/maintenance`.\n",
    "\n",
    "âœ… **DLT Benefits**:\n",
    "- Data quality enforcement using `@dlt.expect`\n",
    "- Easier governance and visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf253b1d-2feb-4bde-abb8-3c651305ed6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"maintenance_events\",\n",
    "    comment=\"Streaming ingestion of maintenance events like routine checks and engine repairs\"\n",
    ")\n",
    "def load_maintenance_events():\n",
    "    maintenance_schema = StructType([\n",
    "        StructField(\"aircraft_id\", StringType(), True),\n",
    "        StructField(\"event_date\", DateType(), True),\n",
    "        StructField(\"event_type\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"pathGlobFilter\", \"*.csv\")\n",
    "        .option(\"cloudFiles.schemaLocation\", \"/Volumes/arao/aerodemo/tmp/maintenance/schema\")\n",
    "        .schema(maintenance_schema)\n",
    "        .load(\"/Volumes/arao/aerodemo/tmp/maintenance\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "641a4ea8-256d-4947-a233-82b543a80895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ”¹ Cleaned Sensor Data\n",
    "\n",
    "This DLT table applies quality filters to the incoming raw sensor data stream to ensure data reliability. The following constraints are enforced:\n",
    "\n",
    "- `engine_temp` must be â‰¤ 700\n",
    "- `fuel_efficiency` must be â‰¥ 50\n",
    "- `vibration` must be â‰¤ 25\n",
    "\n",
    "Additionally, data expectations (`@dlt.expect`) are defined to ensure:\n",
    "- Engine temperature is within 0â€“1000\n",
    "- Fuel efficiency is positive\n",
    "- Vibration is non-negative\n",
    "\n",
    "âœ… **DLT Benefits**:\n",
    "- Streaming data validation\n",
    "- Simplified enforcement of operational thresholds\n",
    "- Automatic schema tracking and lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dec3a11-80cd-47b1-bcd6-2c15a12fe8c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"cleaned_sensor_data\",\n",
    "    comment=\"Cleaned sensor data after applying quality filters and validation on new metrics\"\n",
    ")\n",
    "@dlt.expect(\"valid_engine_temp\", \"engine_temp BETWEEN 0 AND 1000\")\n",
    "@dlt.expect(\"valid_fuel_efficiency\", \"fuel_efficiency > 0\")\n",
    "@dlt.expect(\"valid_vibration\", \"vibration >= 0\")\n",
    "@dlt.expect(\"valid_altitude\", \"altitude BETWEEN 20000 AND 45000\")\n",
    "@dlt.expect(\"valid_airspeed\", \"airspeed BETWEEN 300 AND 600\")\n",
    "@dlt.expect(\"valid_oil_pressure\", \"oil_pressure BETWEEN 20 AND 100\")\n",
    "@dlt.expect(\"valid_engine_rpm\", \"engine_rpm BETWEEN 1000 AND 10000\")\n",
    "@dlt.expect(\"valid_battery_voltage\", \"battery_voltage BETWEEN 22 AND 30\")\n",
    "def cleaned_sensor_data():\n",
    "    return (\n",
    "        dlt.read_stream(\"raw_sensor_data\")\n",
    "        .filter(\n",
    "            (col(\"engine_temp\") <= 700) &\n",
    "            (col(\"fuel_efficiency\") >= 50) &\n",
    "            (col(\"vibration\") <= 25) &\n",
    "            (col(\"altitude\").between(20000, 45000)) &\n",
    "            (col(\"airspeed\").between(300, 600)) &\n",
    "            (col(\"oil_pressure\").between(20, 100)) &\n",
    "            (col(\"engine_rpm\").between(1000, 10000)) &\n",
    "            (col(\"battery_voltage\").between(22, 30))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c6fc416-a6fd-4ce4-8ee9-0bf5e0ee2da8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ”¹ Prediction Results\n",
    "\n",
    "This DLT table performs aggregation on cleaned sensor data to produce a daily risk score per aircraft. The logic includes:\n",
    "\n",
    "- Grouping by `aircraft_id` and `timestamp` (converted to date)\n",
    "- Calculating the average `engine_temp` and `vibration`\n",
    "- Applying a formula to compute a `risk_score`:\n",
    "  \n",
    "  \\[\n",
    "  \\text{{risk_score}} = \\left(\\frac{{\\text{{avg(engine_temp)}}}}{700} + \\frac{{\\text{{avg(vibration)}}}}{25}\\right) \\times 50\n",
    "  \\]\n",
    "\n",
    "âœ… **DLT Benefits**:\n",
    "- Continuous scoring as new sensor data arrives\n",
    "- Built-in aggregation and model-based logic\n",
    "- Enables downstream alerting and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a169b621-c003-434d-963f-9b5e317627e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, avg, to_date\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"prediction_results\",\n",
    "    comment=\"Predicted AOG risk scores using normalized sensor metrics\"\n",
    ")\n",
    "def prediction_results():\n",
    "    df = dlt.read(\"cleaned_sensor_data\")\n",
    "    \n",
    "    return (\n",
    "        df.groupBy(\"aircraft_id\", to_date(\"timestamp\").alias(\"prediction_date\"))\n",
    "        .agg(\n",
    "            (\n",
    "                (avg(\"engine_temp\") / 700) +\n",
    "                (avg(\"vibration\") / 25) +\n",
    "                (1 - avg(\"fuel_efficiency\") / 100) +\n",
    "                (1 - avg(\"oil_pressure\") / 100) +\n",
    "                (avg(\"engine_rpm\") / 10000) +\n",
    "                (1 - avg(\"battery_voltage\") / 30)\n",
    "            * 100 / 6  # Normalize to scale\n",
    "            ).alias(\"risk_score\")\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98080776-0fa1-4cfd-871a-8b5ea82ecf6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "### ðŸ“˜ Enriched Sensor Data with Maintenance Events\n",
    "\n",
    "\n",
    "### ðŸ”¹ Enriched Sensor Data\n",
    "\n",
    "This view joins cleaned sensor records with matching maintenance events on `aircraft_id` and `date(timestamp) = event_date`.\n",
    "\n",
    "Purpose:\n",
    "- Add maintenance context to sensor data\n",
    "- Enable root cause analysis and post-maintenance tracking\n",
    "\n",
    "âœ… **DLT Benefits**:\n",
    "- Built-in lineage from both sensor and maintenance streams\n",
    "- Flexible expansion for ML or analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ccf532c-bfd1-475a-a3bf-1440c8227f21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, to_date, max as spark_max\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Sensor data enriched with most recent maintenance event info\"\n",
    ")\n",
    "def enriched_sensor_data():\n",
    "    cleaned_df = dlt.read(\"cleaned_sensor_data\").withColumn(\"reading_date\", to_date(\"timestamp\"))\n",
    "    events_df = dlt.read(\"maintenance_events\").withColumnRenamed(\"event_date\", \"maint_date\")\n",
    "\n",
    "    # Join on aircraft_id, and filter only maintenance events before or on the sensor reading date\n",
    "    joined = cleaned_df.join(events_df, \"aircraft_id\", \"left\") \\\n",
    "        .filter(col(\"maint_date\") <= col(\"reading_date\"))\n",
    "\n",
    "    # Use window function to get the most recent maintenance event before each reading\n",
    "    window = Window.partitionBy(\"aircraft_id\", \"timestamp\").orderBy(col(\"maint_date\").desc())\n",
    "\n",
    "    result = (joined\n",
    "              .withColumn(\"rank\", F.row_number().over(window))\n",
    "              .filter(col(\"rank\") == 1)\n",
    "              .drop(\"rank\", \"reading_date\"))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36c7600b-b662-4014-8c89-0ff2fea08305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### ðŸ“Š DLT Table: `sensor_features` â€“ Feature Engineering for ML\n",
    "\n",
    "This table generates engineered features from enriched sensor data, designed to support predictive maintenance models. Key aspects include:\n",
    "\n",
    "- **7-day rolling averages** for engine temperature, vibration, and RPM to capture trends over time.\n",
    "- **Lag-based anomaly detection** to provide recent anomaly context.\n",
    "- **Maintenance proximity** (`days_since_maint`) calculated as the number of days since the last known maintenance event.\n",
    "- Selection of core telemetry metrics such as oil pressure, battery voltage, and altitude to give a holistic picture of aircraft health.\n",
    "\n",
    "These features form the foundation for risk scoring, anomaly classification, and machine learning model training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32bd5a96-7e6c-432c-90ea-33c3cee1b290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, avg, lag, to_date\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Engineered sensor features for ML model input\"\n",
    ")\n",
    "def sensor_features():\n",
    "    df = dlt.read(\"enriched_sensor_data\")\n",
    "    df = df.withColumn(\"date\", to_date(\"timestamp\"))\n",
    "\n",
    "    # Define rolling window by aircraft and date (7-day window for averages)\n",
    "    rolling_window = Window.partitionBy(\"aircraft_id\").orderBy(\"date\").rowsBetween(-6, 0)\n",
    "\n",
    "    # Define window for lag without a frame\n",
    "    lag_window = Window.partitionBy(\"aircraft_id\").orderBy(\"date\")\n",
    "\n",
    "    return (\n",
    "        df.withColumn(\"avg_engine_temp_7d\", avg(\"engine_temp\").over(rolling_window))\n",
    "          .withColumn(\"avg_vibration_7d\", avg(\"vibration\").over(rolling_window))\n",
    "          .withColumn(\"avg_rpm_7d\", avg(\"engine_rpm\").over(rolling_window))\n",
    "          .withColumn(\"prev_anomaly\", lag(\"anomaly_score\", 1).over(lag_window))\n",
    "          .withColumn(\"days_since_maint\", F.datediff(\"date\", F.coalesce(F.col(\"maint_date\"), F.lit(\"1970-01-01\"))))\n",
    "          .select(\n",
    "              \"timestamp\", \"aircraft_id\", \"model\", \"engine_temp\", \"fuel_efficiency\", \"vibration\",\n",
    "              \"altitude\", \"airspeed\", \"oil_pressure\", \"engine_rpm\", \"battery_voltage\",\n",
    "              \"anomaly_score\", \"event_type\", \"avg_engine_temp_7d\", \"avg_vibration_7d\",\n",
    "              \"avg_rpm_7d\", \"prev_anomaly\", \"days_since_maint\"\n",
    "          )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DLT_Pipeline_Full",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
